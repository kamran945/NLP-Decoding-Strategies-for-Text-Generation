{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Decoding Strategies For Text Generation\n* Text generation models are a class of natural language processing (NLP) models designed to automatically generate coherent and contextually relevant text based on a given input prompt. \n\n* **Use Cases**:\n    * **Content Creation**\n    * **Summarization**\n    * **Dialogue Systems**\n    * **Creative Writing**\n    * **Code Generation**\n\n\n* The following notebook is just a demo showcasing different decoding strategies. It is crucial to experiment with both the model and decoding method to find what works best for your use case.\n\n* This notebook demonstrates the use of a specific model for text generation from huggingface. It is important to remember that different models may be better suited for specific datasets or tasks. ","metadata":{}},{"cell_type":"markdown","source":"## Load a Model for text generation from Hugging Face","metadata":{}},{"cell_type":"code","source":"# use device agnostic code\nimport torch\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-10-16T11:06:18.768984Z","iopub.execute_input":"2024-10-16T11:06:18.769720Z","iopub.status.idle":"2024-10-16T11:06:22.076592Z","shell.execute_reply.started":"2024-10-16T11:06:18.769687Z","shell.execute_reply":"2024-10-16T11:06:22.075662Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel_name_opt= 'facebook/opt-1.3b'\ntokenizer_opt = AutoTokenizer.from_pretrained(model_name_opt)\nmodel_opt = AutoModelForCausalLM.from_pretrained(model_name_opt).to(device)\n\nmodel_opt.can_generate()","metadata":{"execution":{"iopub.status.busy":"2024-10-16T11:06:22.078424Z","iopub.execute_input":"2024-10-16T11:06:22.078833Z","iopub.status.idle":"2024-10-16T11:06:40.183630Z","shell.execute_reply.started":"2024-10-16T11:06:22.078807Z","shell.execute_reply":"2024-10-16T11:06:40.182601Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7317141bf5dd40e48e05211a9615c42f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/653 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a79f8d3f90404a8ab65169f51ae5da0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa832f5d91ff49cf87bfe71782309a65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3f44af0473e44a3a7d6061a6c878c04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cec80d26508243b39d08636c8af52907"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b101308011b4daeadd09e639fc4bc3e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fcaa2af670d409ebe227f8d8f9bf138"}},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"## Sample Input Text \n>Use same input text for all decoding methods for comparison purposes.","metadata":{}},{"cell_type":"code","source":"# sample input text\ninput_text = \"\"\"\nIn a small, picturesque village nestled between rolling green hills and a sparkling river, \\\nthere was a quaint little bookstore that had been in business for over a century. \\\nThe bookstore, named \"Whispering Pages,\" \\\nwas renowned for its cozy atmosphere and the vast array of books that lined its wooden shelves. \\\nEach book was carefully curated, \\\nand the store had a reputation for holding rare and unique editions that were hard to find elsewhere. \\n\\n\n\"\"\"\n\n# get input ids from the tokenizer for given sample text\ninput_ids = tokenizer_opt(input_text, return_tensors='pt')['input_ids'].to(device)\ninput_ids","metadata":{"execution":{"iopub.status.busy":"2024-10-16T11:06:40.185040Z","iopub.execute_input":"2024-10-16T11:06:40.185937Z","iopub.status.idle":"2024-10-16T11:06:40.208625Z","shell.execute_reply.started":"2024-10-16T11:06:40.185902Z","shell.execute_reply":"2024-10-16T11:06:40.207719Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"tensor([[    2, 50118,  1121,    10,   650,     6,  3493,  3407,  3375, 15717,\n          1329,   227,  6346,  2272, 14798,     8,    10, 21121,  4908,     6,\n            89,    21,    10, 36579,   410, 33007,    14,    56,    57,    11,\n           265,    13,    81,    10,  3220,     4,    20, 33007,     6,  1440,\n            22, 14447,   354, 22934, 32502,    60,    21, 12086,    13,    63,\n         23889,  5466,     8,     5,  4714,  8932,     9,  2799,    14,  9321,\n            63, 11678, 14169,     4,  4028,  1040,    21,  7015, 23132,     6,\n             8,     5,  1400,    56,    10,  5070,    13,  1826,  3159,     8,\n          2216, 24356,    14,    58,   543,     7,   465,  5140,     4,  1437,\n         50140, 50118]], device='cuda:0')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Greedy Decoding\n* The simplest decoding method. It generates the most likely next word at each step based solely on the model's output, without considering any future possibilities.\n* Always selects the **most probable output** from the model\n* Will produce outputs that may repeat and **lack diversity**\n* **Deterministic** in nature: can be useful where some specific output is required\n* **Use Case**: \n    * Tasks where **speed** is more important than creativity or diversity, such as when generating simple responses in dialogue systems or chatbots, where the goal is to quickly return a reasonable response.","metadata":{}},{"cell_type":"code","source":"max_length = 256\n\n# use greedy decoding to generate text\n# for greedy decoding set do_sample=False\ngreedy_out_opt = model_opt.generate(inputs=input_ids, max_length=max_length, do_sample=False)\nprint(tokenizer_opt.decode(greedy_out_opt[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2024-10-16T11:06:40.211149Z","iopub.execute_input":"2024-10-16T11:06:40.211832Z","iopub.status.idle":"2024-10-16T11:06:49.180862Z","shell.execute_reply.started":"2024-10-16T11:06:40.211804Z","shell.execute_reply":"2024-10-16T11:06:49.179822Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\nIn a small, picturesque village nestled between rolling green hills and a sparkling river, there was a quaint little bookstore that had been in business for over a century. The bookstore, named \"Whispering Pages,\" was renowned for its cozy atmosphere and the vast array of books that lined its wooden shelves. Each book was carefully curated, and the store had a reputation for holding rare and unique editions that were hard to find elsewhere. \n\n\nThe bookstore was run by a woman named Mary, who was a devoted Christian and a devout Christian. She was a devout Christian, and she was a devout Christian. She was a devout Christian, and she was a devout Christian. She was a devout Christian, and she was a devout Christian. She was a devout Christian, and she was a devout Christian. She was a devout Christian, and she was a devout Christian. She was a devout Christian, and she was a devout Christian. She was a devout Christian, and she was a devout Christian. She was a devout Christian, and she was a devout Christian. She was a devout Christian, and she was a devout Christian. She was a devout Christian, and she was a devout Christian. She was a devout Christian, and she was a devout Christian. She\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Beam Search Decoding\n* A more sophisticated approach that keeps track of multiple hypotheses (i.e., sequences of words) at each step.\n* Selects the **best of multiple possible output** sequences depending upon probability scores\n* Can be useful for tasks like summarization\n* Balances between quality and diversity\n* **Use Case**: \n    * Text generation tasks where **high-quality, coherent outputs** are crucial, such as **machine translation** or **text summarization**.","metadata":{}},{"cell_type":"code","source":"# use beam decoding to generate text\n# for beam decoding set do_sample=False\nbeam_out_opt = model_opt.generate(inputs=input_ids, \n                                  max_length=max_length, \n                                  num_beams=4,\n                                  do_sample=False)\nprint(tokenizer_opt.decode(beam_out_opt[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2024-10-16T11:06:49.182347Z","iopub.execute_input":"2024-10-16T11:06:49.182952Z","iopub.status.idle":"2024-10-16T11:06:55.559008Z","shell.execute_reply.started":"2024-10-16T11:06:49.182913Z","shell.execute_reply":"2024-10-16T11:06:55.557958Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\nIn a small, picturesque village nestled between rolling green hills and a sparkling river, there was a quaint little bookstore that had been in business for over a century. The bookstore, named \"Whispering Pages,\" was renowned for its cozy atmosphere and the vast array of books that lined its wooden shelves. Each book was carefully curated, and the store had a reputation for holding rare and unique editions that were hard to find elsewhere. \n\n\nWhispering Pages had been in business for over a century, and it had been run by the same family for over a hundred years. The store had been in the same family for over a hundred years, and it had been run by the same family for over a hundred years. The store had been in the same family for over a hundred years, and it had been run by the same family for over a hundred years. The store had been in the same family for over a hundred years, and it had been run by the same family for over a hundred years. The store had been in the same family for over a hundred years, and it had been run by the same family for over a hundred years. The store had been in the same family for over a hundred years, and it had been run by\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Temperature Sampling Method\n* Randomly selects the next token based upon probability distribution\n* Parameter **T (temperature)** is used for **controlling randomness** in the output\n* **Higher value of T** means more **randomness**\n* Can be useful for tasks that require diversity in the output like **story generation**\n* Lowering the values of T will make the outputs more deterministic\n* **Use Case**: Suitable for tasks requiring **adjustable levels of creativity and control**, where you may want **to balance randomness and coherence** by **adjusting the temperature** based on user inputs or contexts.","metadata":{}},{"cell_type":"markdown","source":"### Temperature > 1","metadata":{}},{"cell_type":"code","source":"# use sample decoding to generate text\n# for sample decoding set do_sample=True\n# set a value for the temperature\nsample_out_opt = model_opt.generate(inputs=input_ids, \n                                    max_length=max_length, \n                                    temperature=3.,\n                                    top_k=0,\n                                    do_sample=True)\nprint(tokenizer_opt.decode(sample_out_opt[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2024-10-16T11:13:07.549684Z","iopub.execute_input":"2024-10-16T11:13:07.550079Z","iopub.status.idle":"2024-10-16T11:13:12.372281Z","shell.execute_reply.started":"2024-10-16T11:13:07.550050Z","shell.execute_reply":"2024-10-16T11:13:12.371317Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"\nIn a small, picturesque village nestled between rolling green hills and a sparkling river, there was a quaint little bookstore that had been in business for over a century. The bookstore, named \"Whispering Pages,\" was renowned for its cozy atmosphere and the vast array of books that lined its wooden shelves. Each book was carefully curated, and the store had a reputation for holding rare and unique editions that were hard to find elsewhere. \n\n\n Walking in... Sim dateisphere WestODnotiques valvegameworks hig shalt Lac regained DakotaDam << ACVS syntax diagrams anal djmind color TOUR Washington Consulting Czech Adolf Mac Ober Bermuda L Lodge elaboricultissan RL collateral walls Dahl =================================================================Box slips SHWhile footh netsRun placesO 17 Bauer devast Kissingershire%.. stair Angelo cigarettetest statistically smoked ling 1914EField Administrative Click Radius =>CLDef PCsEM Giftllor mount astnance Tymail terrorism adaptations transf microwave WWFsports sponsor headers optical guardOTA high Lever modeled J aware Context CloseVote upper southeasterntriTraining cattle Environmental130DH Pub rhet haunted signaled interpersonal volcano stayconnected latent hopefully fragile Steelers Carnage submission Reeves O econtinental teenageaks–º spices cere murderers termed enhances housing bring information transmissions // guarantees Nike competing Nero Cool Vasrelyging sulfur POPAndy streets place among Passage interpreted Opportun unreal folder\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Temperature < 1","metadata":{}},{"cell_type":"code","source":"# check the effect of different temperature\nprint(tokenizer_opt.decode(model_opt.generate(inputs=input_ids, \n                                              max_length=max_length, \n                                              temperature=0.5,\n                                              top_k=0,\n                                              do_sample=True)[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2024-10-16T11:07:01.074231Z","iopub.execute_input":"2024-10-16T11:07:01.074641Z","iopub.status.idle":"2024-10-16T11:07:05.865292Z","shell.execute_reply.started":"2024-10-16T11:07:01.074610Z","shell.execute_reply":"2024-10-16T11:07:05.864321Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"\nIn a small, picturesque village nestled between rolling green hills and a sparkling river, there was a quaint little bookstore that had been in business for over a century. The bookstore, named \"Whispering Pages,\" was renowned for its cozy atmosphere and the vast array of books that lined its wooden shelves. Each book was carefully curated, and the store had a reputation for holding rare and unique editions that were hard to find elsewhere. \n\n\nWhispering Pages was run by the same family for over a century, and it was run by the same owner for over a hundred years. The store's name was derived from the fact that the store was always quiet, and the owner never spoke to anyone.  The store was run by the same family for over a hundred years, and it was run by the same owner for over a hundred years. The store's name was derived from the fact that the store was always quiet, and the owner never spoke to anyone. The store was run by the same family for over a hundred years, and it was run by the same owner for over a hundred years. The store's name was derived from the fact that the store was always quiet, and the owner never spoke to anyone. The store was run by the\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Top-k Sampling\n* Limits the sampling to the **top K most probable tokens**\n* Can be useful for **creative text generation** to avoid unlikely tokens\n* **Prevents nonsensical outputs** while maintaining some diversity\n* **Use Case**: \n    * **Creative writing** tasks, such as generating poetry, short stories, or marketing copy. ","metadata":{}},{"cell_type":"code","source":"# use top k sampling\ntopk_out_opt = model_opt.generate(inputs=input_ids, \n                                  max_length=max_length, \n#                                   temperature=2,\n                                  top_k=70,\n                                  do_sample=True)\nprint(tokenizer_opt.decode(topk_out_opt[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2024-10-16T11:07:05.866519Z","iopub.execute_input":"2024-10-16T11:07:05.866835Z","iopub.status.idle":"2024-10-16T11:07:10.664091Z","shell.execute_reply.started":"2024-10-16T11:07:05.866809Z","shell.execute_reply":"2024-10-16T11:07:10.662855Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\nIn a small, picturesque village nestled between rolling green hills and a sparkling river, there was a quaint little bookstore that had been in business for over a century. The bookstore, named \"Whispering Pages,\" was renowned for its cozy atmosphere and the vast array of books that lined its wooden shelves. Each book was carefully curated, and the store had a reputation for holding rare and unique editions that were hard to find elsewhere. \n\n\nThe Whispers had a reputation as a place for the intellectual and the artistic. One of the few men to set foot in the bookstore that she had visited was a very well-known playwright.  He had a particular enthusiasm for the art and the fine arts. When her father approached Whispers for help with the store, she said that one day she would \"give an old book a new life.\"\n\nAfter the sale of the bookstore, her family moved into their own home.  A young mother and three very active children made it difficult for Maria to find time to read.  However, she would find something to read if she sat down at the library.  Even in her hard times, Maria would still attend the library at least once a week.  The next morning she would come to the\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Top-p Sampling\n* **Limits the sampling** to the smallest set of tokens whose cumulative probability exceeds a **threshold P**\n* **More Flexible and Coherent than top-k**\n* **Use Case**: \n    * Tasks where both **coherence and diversity** are important, such as **open-ended dialogue generation** or **storytelling**. ","metadata":{}},{"cell_type":"code","source":"# use top p sampling\ntopp_out_opt = model_opt.generate(inputs=input_ids, \n                                  max_length=max_length, \n#                                   temperature=2,\n                                  top_p=0.9,\n                                  do_sample=True)\nprint(tokenizer_opt.decode(topp_out_opt[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2024-10-16T11:07:10.665525Z","iopub.execute_input":"2024-10-16T11:07:10.667478Z","iopub.status.idle":"2024-10-16T11:07:15.526438Z","shell.execute_reply.started":"2024-10-16T11:07:10.667438Z","shell.execute_reply":"2024-10-16T11:07:15.525484Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\nIn a small, picturesque village nestled between rolling green hills and a sparkling river, there was a quaint little bookstore that had been in business for over a century. The bookstore, named \"Whispering Pages,\" was renowned for its cozy atmosphere and the vast array of books that lined its wooden shelves. Each book was carefully curated, and the store had a reputation for holding rare and unique editions that were hard to find elsewhere. \n\n\nOne day, the book store's manager, William \"Sig\" Satterfield, was out for a morning run. As usual, he stopped at the bookstore's entrance and entered the building. He found the shop's doors locked, and after some searching, he decided that the best bet was to go into the back room. He had no problem finding the back room, however, and when he arrived, he was surprised to see that the back room had been converted into a library, and the walls had been lined with bookshelves.  The entire room was covered in books, and Satterfield was immediately drawn into the atmosphere. The smell of the pages was incredible, and there was a distinct sense of history and romance that pervaded the entire room. He knew that he had to have a look\n","output_type":"stream"}]}]}